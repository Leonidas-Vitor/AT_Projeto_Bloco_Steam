{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import streamlit as st\n",
    "import ast\n",
    "import StreamlitCustomLibrary as at_lib\n",
    "\n",
    "at_lib.SetPageConfig()\n",
    "at_lib.SetTheme()\n",
    "\n",
    "st.header('Preparação dos dados',divider=True)\n",
    "\n",
    "st.markdown(at_lib.GetBasicTextMarkdown(25,\n",
    "    '''\n",
    "    Agora que os dados foram estruturados e pré-preparados iremos fazer algumas investigações e limpezas, pois ainda temos apps\\\n",
    "    inadequados para gerar um modelo de regressão linear adequado.\n",
    "    '''),unsafe_allow_html=True)\n",
    "\n",
    "df_steam = pd.read_csv('SteamDatasetForStreamlitPrepared.csv',engine='pyarrow')\n",
    "st.markdown(at_lib.GetBasicTextMarkdown(20,\n",
    "    f'''\n",
    "    O dataset atualmente possui {df_steam.shape[0]} linhas e {df_steam.shape[1]} colunas.\n",
    "    '''),unsafe_allow_html=True)\n",
    "\n",
    "st.dataframe(df_steam,hide_index=True,height=250)\n",
    "\n",
    "st.divider()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "st.subheader('Remoção de jogos em acesso antecipado',divider=True)\n",
    "\n",
    "cols = st.columns([0.9,0.1])\n",
    "with cols[0]:\n",
    "    st.markdown(at_lib.GetBasicTextMarkdown(20,\n",
    "        '''\n",
    "        Jogos em acesso antecipado possuem um comportamento próprio, pois ainda estão em desenvolvimento e atraem um tipo de público\\\n",
    "        diferente dos jogos já lançados. Por isso, iremos remover esses jogos do dataset, pois não queremos que eles influenciem\\\n",
    "        o modelo de regressão linear será focado para jogos totalmente lançados.\n",
    "        '''),unsafe_allow_html=True)\n",
    "with cols[1]:\n",
    "    earlyAcessCount = df_steam[df_steam['isEarlyAcess']==True]['id'].count()\n",
    "    earlyAcessPercent = (earlyAcessCount/df_steam['id'].count())*100\n",
    "    st.metric(label=\"Jogos removidos\", value=f'{earlyAcessCount}', delta=f'-{earlyAcessPercent:.2f}%')\n",
    "\n",
    "with st.expander('Jogos em acesso antecipado'):\n",
    "    st.dataframe(df_steam[df_steam['isEarlyAcess']==True][['name','id','isEarlyAcess']],hide_index=True,height=250,use_container_width=True)\n",
    "\n",
    "df_steam = df_steam[df_steam['isEarlyAcess']==False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de apps VR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "st.subheader('Remoção de apps VR',divider=True)\n",
    "\n",
    "forbiddenTag = ['VR']\n",
    "df_steam['ContainForbiddenTag'] = df_steam['tags'].apply(lambda x: any(tag in x for tag in forbiddenTag))\n",
    "cols = st.columns([0.9,0.1])\n",
    "with cols[0]:\n",
    "    st.markdown(at_lib.GetBasicTextMarkdown(20,\n",
    "        '''\n",
    "        Esse modelo de regressão não irá contemplar jogos/apps de realidade virtual portanto iremos remove-los do dataset.\n",
    "        '''),unsafe_allow_html=True)\n",
    "\n",
    "with cols[1]:\n",
    "    forbiddenTagCount = df_steam[df_steam['ContainForbiddenTag']==True]['id'].count()\n",
    "    forbiddenTagPercent = (forbiddenTagCount/df_steam['id'].count())*100\n",
    "    st.metric(label=\"Jogos removidos\", value=f'{forbiddenTagCount}', delta=f'-{forbiddenTagPercent:.2f}%')\n",
    "\n",
    "with st.expander('Apps vr removidos'):\n",
    "    st.dataframe(df_steam[df_steam['ContainForbiddenTag']==True][['name','id','tags']],hide_index=True,height=250,use_container_width=True)\n",
    "\n",
    "df_steam = df_steam[df_steam['ContainForbiddenTag']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de apps com tags indevidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "st.subheader('Remoção de não jogos',divider=True)\n",
    "\n",
    "forbiddenTags = ['Game Development', 'Utilities','Software'] #'Animation & Modeling','Photo Editing','Video Production'\n",
    "df_steam['ContainForbiddenTag'] = df_steam['tags'].apply(lambda x: any(tag in x for tag in forbiddenTags))\n",
    "\n",
    "cols = st.columns([0.9,0.1])\n",
    "with cols[0]:\n",
    "    st.markdown(at_lib.GetBasicTextMarkdown(20,\n",
    "        f'''\n",
    "        O dataset ainda possui apps que não são jogos, como softwares de modelagem 3D e utilitários, e por serem classificados\\\n",
    "        pela loja como \\\"game\\\" na antiga coluna \\\"type\\\" eles ainda estão presentes no dataset. Iremos remove-los utilizando uma\\\n",
    "        lista de tags normalmente associdas a esses tipos de apps.\n",
    "        '''),unsafe_allow_html=True)\n",
    "    st.markdown(at_lib.GetBasicTextMarkdown(15,\n",
    "        f'''\n",
    "        {forbiddenTags}\n",
    "        '''),unsafe_allow_html=True)\n",
    "\n",
    "with cols[1]:\n",
    "    forbiddenTagCount = df_steam[df_steam['ContainForbiddenTag']==True]['id'].count()\n",
    "    forbiddenTagPercent = (forbiddenTagCount/df_steam['id'].count())*100\n",
    "    st.metric(label=\"Jogos removidos\", value=f'{forbiddenTagCount}', delta=f'-{forbiddenTagPercent:.2f}%')\n",
    "\n",
    "with st.expander('Apps com tags indevidas'):\n",
    "    st.dataframe(df_steam[df_steam['ContainForbiddenTag']==True][['name','id','tags']],hide_index=True,height=250,use_container_width=True)\n",
    "\n",
    "df_steam = df_steam[df_steam['ContainForbiddenTag']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "st.subheader('Remoção de playtests',divider=True)\n",
    "\n",
    "df_steam['isPlaytest'] = df_steam['name'].apply(lambda n: 'Playtest' in n if n != None else False)\n",
    "\n",
    "st.dataframe(df_steam[df_steam['isPlaytest'] == True],hide_index=True,height=250,use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preenchendo as durações faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "st.subheader('Preenchendo as durações ausentes',divider=True)\n",
    "\n",
    "st.markdown(at_lib.GetBasicTextMarkdown(20,\n",
    "    '''\n",
    "    Existe uma grande ausência de dados de duração, para resolver esse problema iremos inferir os dados faltantes\\\n",
    "    através da mediana da duração dos jogos do mesmo gênero. Jogos que tiverem uma similaridade de nome menor que\\\n",
    "    0.9 também serão substituídos pela mediana do gênero, já que seus dados não são confiáveis.\n",
    "    '''),unsafe_allow_html=True)\n",
    "\n",
    "df_duration_median = df_steam[(df_steam['total_duration'] > 0) & (~np.isnan(df_steam['total_duration'])) &\n",
    "    (df_steam['hltb_similarity'] > 0.9)].copy()\n",
    "\n",
    "df_duration_median = df_duration_median[['main_genre','total_duration']]\n",
    "df_duration_median = df_duration_median.groupby('main_genre').median().reset_index()\n",
    "\n",
    "st.dataframe(df_duration_median,use_container_width=True)\n",
    "\n",
    "def FillDuration(row):\n",
    "    if (row['total_duration'] == 0 or np.isnan(row['total_duration']) or type(row['total_duration']) == str):\n",
    "        row['total_duration'] = df_duration_median[df_duration_median['main_genre'] == row['main_genre']]['total_duration'].values[0]\n",
    "    return row\n",
    "\n",
    "df_steam = df_steam.apply(FillDuration,axis=1)\n",
    "\n",
    "df_steam.drop(columns=['hltb_similarity'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a 'C:\\Users\\leoni\\OneDrive\\Documentos\\AT_Projeto_Bloco_Streamlit\\DataCleaning.py'\n",
    "\n",
    "st.markdown(at_lib.GetBasicTextMarkdown(20,\n",
    "    f'''\n",
    "    O dataset atualmente possui {df_steam.shape[0]} linhas e {df_steam.shape[1]} colunas.\n",
    "    '''),unsafe_allow_html=True)\n",
    "\n",
    "st.dataframe(df_steam,hide_index=True,height=250)\n",
    "\n",
    "st.table(df_steam.set_index('id').describe())\n",
    "\n",
    "st.download_button(\n",
    "    label=\"Baixar o dataset preparado\",\n",
    "    data=df_steam.to_csv(index=False),\n",
    "    file_name='SteamDatasetForStreamlitClean.csv',\n",
    "    mime='text/csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remover acesso antecipado\n",
    "- Investigar outliers brabos e remover eles\n",
    "- Preencher os dados faltantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INFNET_II",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
